# Using seed to generate reproducible results
set.seed(4233)
# Create iterative loop to plug in different values of nodesize and mtry to find most accurate model, i.e., the model with the smallest r^2 value
result.rf <- data.frame(matrix(nrow=5, ncol=3))
colnames(result.rf) <- c("NodeSize", "mtry", "R2")
i = 1
suppressWarnings(for (nodesize in 2:15) {
for (m in 1:20) {
model <- randomForest(Crime ~ ., data=data_crime, importance = TRUE, nodesize = nodesize, mtry = m)
predict <- predict(model, data=data_crime[,-16])
RSS <- sum((predict - data_crime[,16])^2)
TSS <- sum((data_crime[,16] - mean(data_crime[,16]))^2)
R2 <- 1 - RSS/TSS
result.rf[i,1] <- nodesize
result.rf[i,2] <- m
result.rf[i,3] <- R2
i = i + 1
}
})
head(result.rf)
result.rf[which.max(result.rf[,3]),]
# Plugged these values into our model
crime.rf.final <- randomForest(Crime ~ ., data=data_crime, importance = TRUE, nodesize = 2, mtry = 3)
# Review the most important variables
importance(crime.rf.final)
varImpPlot(crime.rf.final)
# Using seed to generate reproducible results
set.seed(4233)
credit <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data", header = FALSE)
str(credit)
# Replace 1s and 2s with 0s and 1s
credit$V21[credit$V21==1] <- 0
credit$V21[credit$V21==2] <- 1
# Split data into train and validation set
creditTrain <- credit[1:800,]
creditTest <- credit[801:1000,]
print(creditTest)
# Using seed to generate reproducible results
set.seed(4233)
creditLogModel <- glm(V21 ~ ., data = creditTrain, family=binomial(link="logit"))
# Using summary function to review predictors
summary(creditLogModel)
# Using seed to generate reproducible results
set.seed(4233)
#Let's do a baseline prediction.
creditPredict <- predict(creditLogModel, newdata=creditTest, type="response")
print(creditTest$V21, base::round(creditPredict))
creditPredict
creditTest$V21
print(creditTest$V21, base::round(creditPredict))
print(paste(creditTest$V21, base::round(creditPredict)))
# Using summary function to review predictors
summary(creditLogModel)
# Using seed to generate reproducible results
set.seed(4233)
#Let's do a baseline prediction.
creditPredict <- predict(creditLogModel, newdata=creditTest, type="response")
print(paste(creditTest$V21, base::round(creditPredict)))
# loading all packages needed for analysis
library(kernlab)
library(kknn)
library(dplyr)
library(readr)
library(rmarkdown)
library(tinytex)
library(knitr)
library(NbClust)
library(outliers)
library(nortest)
library(greybox)
library(Mcomp)
library(DAAG)
library(caret)
library(randomForest)
library(tree)
library(pROC)
# description: http://www.statsci.org/data/general/uscrime.html
# import data from URL
data_crime <- read.table("http://www.statsci.org/data/general/uscrime.txt", stringsAsFactors = FALSE, header = TRUE)
# print head
print(data_crime)
# Using seed to generate reproducible results
set.seed(4233)
# Principal Component Analysis
pca_analysis <- prcomp(data_crime[,1:15], center=T, scale.=T)
summary(pca_analysis)
# Printing the matrix of eigenvectors
head(pca_analysis$rotation)
# Printing list of PCAs
head(pca_analysis$x)
# Square the standard deviation
std_squar <- pca_analysis$sdev^2
# Then calculate the proportional variance by dividing each eigenvalue by the sum of all eigenvalues
propor_var <- std_squar/sum(std_squar)
plot(propor_var, xlab = "Principal Component", ylab = "Proportion of Variance", ylim = c(0,1) , type= "b")
# To determine which PC variables are the most important, we will use the Kaiser rule, which asserts that any standard deviation listed
# that is greater than 1 is important.
screeplot(pca_analysis, main = "Scree Plot", type = "line")
abline(h=1, col="red")
# Setting r^2 value and 5-fold cross-validated r^2 values
r2 <- numeric(15)
r2cross_val <- numeric(15)
# Using seed to generate reproducible results
set.seed(4233)
# To determine the number of PCs which wil give us the most accurate model, we will run an iterative loop to calculate r^2 and 5-fold cross-validated r^2 values using all PC values from 1 up to 15.
for (i in 1:15){
pc_list <- pca_analysis$x[,1:i]
pcc <- cbind(data_crime[,16],pc_list)
# Calculate r^2, and append the values to the appropriate list
model <- lm(V1~., data = as.data.frame(pcc))
r2[i] <- 1 -sum(model$residuals^2)/sum((data_crime$Crime - mean(data_crime$Crime))^2)
# Calculate 5-fold cross-validated r^2 values, and append the values to the appropriate list
par(mfrow = c(3,5))
c <- cv.lm(as.data.frame(pcc), model, m = 5, plotit = TRUE, printit = FALSE)
r2cross_val[i] <- 1 - attr(c,"ms")*nrow(data_crime) / sum((data_crime$Crime - mean(data_crime$Crime))^2)
}
#plot the results
plot(r2,xlab = "Principal Component",ylab = "R^2 at x Principal Components", ylim = c(0,1), type = "b", col = "blue")
# Will store the above data in a data frame for further review.
review_r2 <- data.frame(r2, r2cross_val, c(1:length(r2)))
print(review_r2)
# Set k equal to 5.
k  = 5
# Using the cbind(), we will combine 1 through 5 PCs with our original crime data.
pc_crime <- cbind(pca_analysis$x[,1:k], data_crime[,16])
# Using seed to generate reproducible results
set.seed(4233)
# Will create a linear regression model
lm_model <- lm(V6~., data = as.data.frame(pc_crime))
summary(lm_model)
plot(lm_model)
# Will first obtain intercepts for our transformation
beta0 <- lm_model$coefficients[1]
# Will then pull out our model's coefficients in order to construct the Beta vector
betas <- lm_model$coefficients[2:(k+1)]
# Multiply the coefficients by our rotatation matrix to create the Alpha vector
alpha <- pca_analysis$rotation[,1:k] %*% betas
# We can then obtain the original alpha values by dividing the alpha vector by sigma
mu <- sapply(data_crime[,1:15],mean)
sigma <- sapply(data_crime[,1:15],sd)
origAlpha <- alpha/sigma
# We can then obtain our original beta values by subtracting from the sum of (alpha*mu)/sigma from the intercept
origBeta0 <- beta0 - sum(alpha*mu /sigma)
# We can now create our model in the form of y = ax + b, where a is the scaled alpha value and b is the original intercept
estimates <- as.matrix(data_crime[,1:15]) %*% origAlpha + origBeta0
# To determine the accuracy of this model, we will now calculate our r^2
SSE = sum((estimates - data_crime[,16])^2)
SStot = sum((data_crime[,16] - mean(data_crime[,16]))^2)
R2 <- 1 - SSE/SStot
print(R2)
# To determine the accuracy of this model, we will now calculate our adjested r^2
R2_adjust <- R2 - (1-R2)*k/(nrow(data_crime)-k-1)
R2_adjust
# Using the data provided last week, we can see how our new model predicts the crime rate
last_week_city <- data.frame(M= 14.0, So = 0, Ed = 10.0, Po1 = 12.0, Po2 = 15.5,
LF = 0.640, M.F = 94.0, Pop = 150, NW = 1.1, U1 = 0.120, U2 = 3.6, Wealth = 3200, Ineq = 20.1, Prob = 0.040,Time = 39.0)
# Using seed to generate reproducible results
set.seed(4233)
# Creating a data frame with PCA data and last week's city data
pred_df <- data.frame(predict(pca_analysis, last_week_city))
# Crime rate prediction
pred <- predict(lm_model, pred_df)
print(pred)
# Using seed to generate reproducible results
set.seed(4233)
# Will first construct a regression tree model using the tree() function
crimeTreeMod <- tree(Crime ~ ., data = data_crime)
summary(crimeTreeMod)
# Will plot the tree to review model
crimeTreeMod$frame
plot(crimeTreeMod)
text(crimeTreeMod)
title("USCRIME Training Set's Classification Tree")
# Using seed to generate reproducible results
set.seed(4233)
# To further model's accuracy, will prune the tree
termnodes <- 5
prune.crimeTreeMod <- prune.tree(crimeTreeMod, best = termnodes)
plot(prune.crimeTreeMod)
text(prune.crimeTreeMod)
title("Pruned Tree")
summary(prune.crimeTreeMod)
# Look at the deviation and do cross validation
cv.crime <- cv.tree(crimeTreeMod)
prune.tree(crimeTreeMod)$size
prune.tree(crimeTreeMod)$dev
cv.crime$dev
# The plot backs up our overfitting suspicion
plot(cv.crime$size, cv.crime$dev, type = "b")
# Will use the max number of terminal nodes, as it contains the smallest amount of errors
termnodes2 <- 7
prune.crimeTreeMod2 <- prune.tree(crimeTreeMod, best = termnodes2)
plot(prune.crimeTreeMod2)
text(prune.crimeTreeMod2)
title("Pruned Tree")
summary(prune.crimeTreeMod2)
# Using seed to generate reproducible results
set.seed(4233)
# Will determine fit quality
crimeTreePredict <- predict(prune.crimeTreeMod2, data = uscrime[,1:15])
RSS <- sum((crimeTreePredict - data_crime[,16])^2)
TSS <- sum((data_crime[,16] - mean(data_crime[,16]))^2)
R2 <- 1 - RSS/TSS
R2
# Will next construct a random forest model using the randomForest() function
# Using seed to generate reproducible results
set.seed(4233)
# Creating baseline randomForest Model
crime.rf <- randomForest(Crime ~ ., data=data_crime, importance = TRUE, nodesize = 5)
crime.rf.predict <- predict(crime.rf, data=data_crime[,-16])
RSS <- sum((crime.rf.predict - data_crime[,16])^2)
R2 <- 1 - RSS/TSS
R2
# Using seed to generate reproducible results
set.seed(4233)
# Our r^2 is even worse than our previous tree. Will try a value of 9 for mtry and see how this affects accuracy
crime.rf2 <- randomForest(Crime ~ ., data=data_crime, importance = TRUE, nodesize = 5, mtry = 9)
crime.rf.predict2 <- predict(crime.rf2, data=data_crime[,-16])
RSS <- sum((crime.rf.predict2 - data_crime[,16])^2)
R2 <- 1 - RSS/TSS
R2
# Using seed to generate reproducible results
set.seed(4233)
# Create iterative loop to plug in different values of nodesize and mtry to find most accurate model, i.e., the model with the smallest r^2 value
result.rf <- data.frame(matrix(nrow=5, ncol=3))
colnames(result.rf) <- c("NodeSize", "mtry", "R2")
i = 1
suppressWarnings(for (nodesize in 2:15) {
for (m in 1:20) {
model <- randomForest(Crime ~ ., data=data_crime, importance = TRUE, nodesize = nodesize, mtry = m)
predict <- predict(model, data=data_crime[,-16])
RSS <- sum((predict - data_crime[,16])^2)
TSS <- sum((data_crime[,16] - mean(data_crime[,16]))^2)
R2 <- 1 - RSS/TSS
result.rf[i,1] <- nodesize
result.rf[i,2] <- m
result.rf[i,3] <- R2
i = i + 1
}
})
head(result.rf)
result.rf[which.max(result.rf[,3]),]
# Plugged these values into our model
crime.rf.final <- randomForest(Crime ~ ., data=data_crime, importance = TRUE, nodesize = 2, mtry = 3)
# Review the most important variables
importance(crime.rf.final)
varImpPlot(crime.rf.final)
# Using seed to generate reproducible results
set.seed(4233)
credit <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data", header = FALSE)
str(credit)
# Replace 1s and 2s with 0s and 1s
credit$V21[credit$V21==1] <- 0
credit$V21[credit$V21==2] <- 1
# Split data into train and validation set
creditTrain <- credit[1:800,]
creditTest <- credit[801:1000,]
print(creditTest)
# Using seed to generate reproducible results
set.seed(4233)
creditLogModel <- glm(V21 ~ ., data = creditTrain, family=binomial(link="logit"))
# Using summary function to review predictors
summary(creditLogModel)
# Using seed to generate reproducible results
set.seed(4233)
#Let's do a baseline prediction.
creditPredict <- predict(creditLogModel, newdata=creditTest, type="response")
print(paste(creditTest$V21, base::round(creditPredict)))
# Manually removing non-significant variables from training data set
creditTrain$V1A14[creditTrain$V1 == "A14"] <- 1
creditTrain$V1A14[creditTrain$V1 != "A14"] <- 0
creditTrain$V3A34[creditTrain$V3 == "A34"] <- 1
creditTrain$V3A34[creditTrain$V3 != "A34"] <- 0
creditTrain$V4A41[creditTrain$V4 == "A41"] <- 1
creditTrain$V4A41[creditTrain$V4 != "A41"] <- 0
creditTrain$V4A43[creditTrain$V4 == "A43"] <- 1
creditTrain$V4A43[creditTrain$V4 != "A43"] <- 0
# Using seed to generate reproducible results
set.seed(4233)
creditLogModel2 <- glm(V21 ~ V1A14+V2+V3A34+V4A41+V4A43, data = creditTrain, family=binomial(link="logit"))
summary(creditLogModel2)
# Processing the test data set in the same way
creditTest$V1A14[creditTest$V1 == "A14"] <- 1
creditTest$V1A14[creditTest$V1 != "A14"] <- 0
creditTest$V3A34[creditTest$V3 == "A34"] <- 1
creditTest$V3A34[creditTest$V3 != "A34"] <- 0
creditTest$V4A41[creditTest$V4 == "A41"] <- 1
creditTest$V4A41[creditTest$V4 != "A41"] <- 0
creditTest$V4A43[creditTest$V4 == "A43"] <- 1
creditTest$V4A43[creditTest$V4 != "A43"] <- 0
# Will now create confusion matrix of predicted vs. observed values on the test set
creditPredict2 <- predict(creditLogModel2, newdata=creditTest[,-21], type="response")
t <- as.matrix(base::table(round(creditPredict2), creditTest$V21))
names(dimnames(t)) <- c("Predicted", "Observed")
print(t)
# Will now calculate both accuracy and specificity, with the goal of maximizing specificity realtive to the effect of a false positive
threshold <- 0.7
t2 <- as.matrix(base::table(round(creditPredict2 > threshold), creditTest$V21))
names(dimnames(t2)) <- c("Predicted", "Observed")
print(t2)
accuracy <- (t2[1,1]+t2[2,2])/(t2[1,1]+t2[1,2]+t2[2,1]+t2[2,2])
print(accuracy)
specificity <- (t2[1,1])/(t2[1,1]+t2[2,1])
print(specificity)
# Setting r^2 value and 5-fold cross-validated r^2 values
r2 <- numeric(15)
r2cross_val <- numeric(15)
# Using seed to generate reproducible results
set.seed(4233)
# To determine the number of PCs which wil give us the most accurate model, we will run an iterative loop to calculate r^2 and 5-fold cross-validated r^2 values using all PC values from 1 up to 15.
for (i in 1:15){
pc_list <- pca_analysis$x[,1:i]
pcc <- cbind(data_crime[,16],pc_list)
# Calculate r^2, and append the values to the appropriate list
model <- lm(V1~., data = as.data.frame(pcc))
r2[i] <- 1 -sum(model$residuals^2)/sum((data_crime$Crime - mean(data_crime$Crime))^2)
# Calculate 5-fold cross-validated r^2 values, and append the values to the appropriate list
par(mfrow = c(3,5))
c <- cv.lm(as.data.frame(pcc), model, m = 5, plotit = FALSE, printit = FALSE)
r2cross_val[i] <- 1 - attr(c,"ms")*nrow(data_crime) / sum((data_crime$Crime - mean(data_crime$Crime))^2)
}
# loading all packages needed for analysis
library(kernlab)
library(kknn)
library(dplyr)
library(readr)
library(rmarkdown)
library(tinytex)
library(knitr)
library(NbClust)
library(outliers)
library(nortest)
library(greybox)
library(Mcomp)
library(DAAG)
library(caret)
library(randomForest)
library(tree)
library(pROC)
library(glmnet)
packageurl <- "https://cran.r-project.org/src/contrib/Archive/sme/sme_1.0.2.tar.gz"
install.packages(packageurl, repos=NULL, type="source")
library(FrF2)
install.packages("FrF2")
# loading all packages needed for analysis
library(kernlab)
library(kknn)
library(dplyr)
library(readr)
library(rmarkdown)
library(tinytex)
library(knitr)
library(NbClust)
library(outliers)
library(nortest)
library(greybox)
library(Mcomp)
library(DAAG)
library(caret)
library(randomForest)
library(tree)
library(pROC)
library(glmnet)
packageurl <- "https://cran.r-project.org/src/contrib/Archive/sme/sme_1.0.2.tar.gz"
install.packages(packageurl, repos=NULL, type="source")
library(FrF2)
install.packages("gmp")
# loading all packages needed for analysis
library(kernlab)
library(kknn)
library(dplyr)
library(readr)
library(rmarkdown)
library(tinytex)
library(knitr)
library(NbClust)
library(outliers)
library(nortest)
library(greybox)
library(Mcomp)
library(DAAG)
library(caret)
library(randomForest)
library(tree)
library(pROC)
library(glmnet)
packageurl <- "https://cran.r-project.org/src/contrib/Archive/sme/sme_1.0.2.tar.gz"
install.packages(packageurl, repos=NULL, type="source")
packageurl2 <- "https://cran.r-project.org/bin/windows/contrib/4.2/gmp_0.6-10.zip"
install.packages(packageurl2, repos=NULL, type="source")
library(FrF2)
# description: http://www.statsci.org/data/general/uscrime.html
# import data from URL
data_crime <- read.table("http://www.statsci.org/data/general/uscrime.txt", stringsAsFactors = FALSE, header = TRUE)
# print head
print(data_crime)
# Loading all packages needed for analysis
library(kernlab)
library(kknn)
library(dplyr)
library(readr)
library(rmarkdown)
library(tinytex)
library(knitr)
library(NbClust)
library(outliers)
library(nortest)
library(mice)
library(Mcomp)
library(DAAG)
library(caret)
library(randomForest)
library(tree)
library(pROC)
library(ggplot2)
library(VIM)
cancer_data = read_delim("C:\\Users\\Owner\\Documents\\Github\\r\\class assignments\\Introduction to Statistical Modeling\\Assignment 6\\data\\breast-cancer-wisconsin.data.txt",
delim = ',',
col_names = F, na = c('?')) %>%
as.data.frame() %>%
mutate(X11 = ifelse(X11 == 2, 'Benign', 'Malignant'))
head(cancer_data)
# Loading all packages needed for analysis
library(kernlab)
library(kknn)
library(dplyr)
library(readr)
library(rmarkdown)
library(tinytex)
library(knitr)
library(NbClust)
library(outliers)
library(nortest)
library(mice)
library(Mcomp)
library(DAAG)
library(caret)
library(randomForest)
library(tree)
library(pROC)
library(ggplot2)
library(VIM)
cancer_data = read_delim("C:\\Users\\Owner\\Documents\\Github\\r\\class assignments\\Introduction to Statistical Modeling\\Assignment 6\\data\\breast-cancer-wisconsin.data.txt",
delim = ',',
col_names = F, na = c('?')) %>%
as.data.frame() %>%
mutate(X11 = ifelse(X11 == 2, 'Benign', 'Malignant'))
head(cancer_data)
# Statistical summary of data
summary(cancer_data)
# Will use mice() function to locate column with missing data and render visually
missing_print <- md.pattern(cancer_data[,-11])
print(missing_print)
# Looks like V7 has missing values.
# Plotting the missing data
plot_missing_values <- aggr(cancer_data, col = c('green', 'red'), numbers = TRUE, sortVars = TRUE)
# Using seed to generate reproducible results
set.seed(4233)
# Will use mice() function to do mean imputation
cancer_data_mean_impute <- mice(cancer_data, m = 5, meth = 'mean')
print(cancer_data_mean_impute$imp)
# Using seed to generate reproducible results
set.seed(4233)
# Will impute missing data points using mice() function. Using 'norm.predict', or the linear regression, predicted values method for this
cancer_data_regression_impute <- mice(cancer_data, m = 5, meth = 'norm.predict')
print(cancer_data_regression_impute$imp)
# Using seed to generate reproducible results
set.seed(4233)
# Will impute missing data points using mice() function. Using 'norm.nob', to do perturbation imputation
cancer_data_pertubation_impute <- mice(cancer_data, m = 5, meth = 'norm.nob')
print(cancer_data_pertubation_impute$imp)
# Converting implicit missing values into explicit missing values with the complete() function for all three imputations
cancer_mean_impute <- complete(cancer_data_mean_impute)
cancer_regression_impute <- complete(cancer_data_regression_impute)
cancer_pertubation_impute <- complete(cancer_data_pertubation_impute)
# Will create list containing datasets, and use random forest method to compare cross validation accuracy of each model
cancer_data_sets = list(cancer_data, cancer_mean_impute, cancer_regression_impute, cancer_pertubation_impute)
# Created list to contain accuracy outputs after iteration
cancer_final_val_output = list(no_imputation = NULL, mean_imputation = NULL, regression_imputation = NULL,
pertubation_imputation = NULL)
# Using training method, will iterate loop to fit each model via the random forest method, then print accuracy percentages for each and load into "list" cancer_final_val_output" list above
for (i in seq_along(cancer_data_sets)) {
df = cancer_data_sets[[i]]
# Using seed to generate reproducible results
set.seed(4233)
# Classification results
in_td <- createDataPartition(df$X11, p = .75, list = FALSE)
# Splitting data for training and test datasets
train <- df[in_td , ] %>% na.omit()
test <- df[-in_td ,] %>% na.omit()
# Fitting model
cancer_model_fit <- train(
X11 ~ .,
method = 'rf',
data = train,
metric = 'Accuracy',
trControl = trainControl(
method = 'cv',
number = 10
)
)
cancer_final_val_output[[i]] = cancer_model_fit
}
# Print and view the results of each model and compare cross validation accuracy of each output
no_imp <- cancer_final_val_output$no_imputation$finalModel
mean_imp <- cancer_final_val_output$mean_imputation$finalModel
regress_imp <- cancer_final_val_output$regression_imputation$finalModel
pert_imp <- cancer_final_val_output$pertubation_imputation$finalModel
print(no_imp)
print(mean_imp)
print(regress_imp)
print(pert_imp)
